# 개요
고객의 이탈을 예측하는 모델을 만들기 위해 DNN을 통해 생성할 수도 있지만, 고전적인 학습 방법을 통해 베이스라인 모델을 만들고, 이를 지속적으로 개선하는 방향으로 학습을 하고자 한다.

## 단계
* (2017/11/25) 가장 기본적인 지표를 최소한의 데이터만 생성하여 학습을 수행한다
    * Playtime, LogCount, ExpAmount, MoneyAmount 값을 유저 별 일별 지표를 추출
    * 해당 값을 그대로 사용하면 이용자 별 학습이 되지 않으니, 하나의 숫자로 선형회귀식을 구하고 기울기 값을 특질로 삼는다
* (2017/11/26) 추출된 데이터를 통해 [Weka Toolkit](https://www.cs.waikato.ac.nz/ml/weka)을 통해서 학습
    * Decision Tree, LibSVM 등의 고전적인 학습 알고리즘 적용
```bash
                === Detailed Accuracy By Class ===
                TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                0.508    0.159    0.578      0.508    0.541      0.363    0.702     0.503     churn
                0.841    0.494    0.798      0.841    0.819      0.361    0.700     0.805     not_churn
                0.000    0.000    0.000      0.000    0.000      0.000    0.450     0.001     undefined
Weighted Avg.   0.740    0.393    0.731      0.740    0.734      0.361    0.700     0.714     
```
    * 테스트에 사용된 학습 데이터는 약 800건 (traindata_1 폴더)만 사용하였고, F-measure 73% 정도를 보여줌
    * 고전적인 방법의 접근은은 Naive 한 수준이지만 학습용 데이터에서는 약 73%정도의 성능을 보여준다 
* (2017/11/29) 동일한 학습 데이터를 통해서 텐서플로우를 이용하여 학습
    * 테스트의 경우 DNN이 아니라 네트워크가 1레벨이므로 단순 Linear Regression 이었음
    * 정확도: 30.00%
* (2017/11/30) 딥뉴럴 네트워크 학습 실행
    * 가장 기본적인 DNN 네트워크 구성하여 실습 (2레벨 4=>10=>20=>3)
    * 비슷하거나 조금 더 좋은 결과가 나올 것으로 예상
    * 정확도: 53.88% => 2레벨 20~50노드
    * 정확도: 73.38% => 레벨의 수를 3레벨로 높이는 순간 베이스라인 수준까지 올라왔음
    * 정확도: 76.50% => 노드의 수를 늘리고 배치 수를 늘렸는데 50% 대로 떨어져서 노드의 수는 20개로 줄이고 배치수를 늘렸음
    * 정확도: 72.20% => 배치수를 늘림에 따라 Cost 가 줄어들지만 정확률이 떨어지는 현상 발생
    * 정확도: 73.38% => 배치수를 오히려 1000으로 하면 73% (10, 10, 10, 2000) - 할 때마다 동일한 상황에서 다른 결과가 나오고 있음
* (2017/12/01) 반복적인 실험
    * 동일한 학습 파라메터로 정확률이 50~70% 수준으로 변경되므로 초기화에 따라 다르다는 판단
    * 생각보다 파라메터 자체의 초기화, 혹은 하이퍼 파라메터에 따른 학습 결과의 편차가 크다는 느낌
* (2017/12/02) 반복적인 실험2
    * 학습이 튀는 현상의 원인은 learning\_rate 값이 너무 커서 (0.01) 였던 것 같다 학습률을 1/10 정도(0.0005) 수준으로 낮추니 튀는 현상이 거의 없어졌음
    * 학습을 반복하더라도 좋아지지 않는 것은 학습 데이터가 충분히 크지 않기 때문이다 즉, epoch을 충분히 넘어버려서 더 이상 의미가 없는 것으로 판단됨
    * 4000개의 데이터를 모두 생성하여 학습해 보았으나, 정확률에서 큰 차이가 나지 않았음. 특질을 더 추가해야 할 것으로 판단됨
    * 노드 수를 늘리고, epoch 수를 높이니 75%까지 성능이 향상되었음
    * 그 이상 잘 안 올라갔으나 dropout 비율을 낮추니 (0.8, 0.7, 0.6) 성능 향상에 도움이 되었다 80% 까지 향상
* (2017/12/?) 테스트 데이터를 통해서 결과물의 수준을 대회 결과와 비교
    * 고전적인 방식의 테스트 결과 비교
    * DNN 통한 방식의 테스트 결과 비교
* 학습 데이터 생성 및 학습 과정을 자동화
    * 데이터 생성을 조금 더 빨리, 효율적으로 수행할 수 있도록 개선
    * 더 많은 기간의 데이터를 이용하여 학습 및 테스트
    * 학습과 테스트 과정을 항상 자동화 하여 생산성 향상
        - S3에 데이터를 저장하면 트리거링 되어서 학습을 위한 데이터가 생성
        - S생성된 데이터를 텐서플로우 로컬을 통해서 학습 및 모델 생성
        - S모델이 생성되면 트리거링 되어서 테스트 데이터에 대한 검증까지 수행

